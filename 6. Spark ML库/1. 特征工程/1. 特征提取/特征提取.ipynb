{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c7a366a",
   "metadata": {},
   "source": [
    "### 特征提取"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f74fca2",
   "metadata": {},
   "source": [
    "#### TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209f3e90",
   "metadata": {},
   "source": [
    "**Term frequency-inverse document frequency (TF-IDF)**是在文本挖掘中常用的特征向量化方法，用来反映一个**单词（term）**在**语料库（corpus）**中对于一个**文档（document）**的重要程度。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b44ef9",
   "metadata": {},
   "source": [
    "标记单词为t，文档为d，语料库为D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89b19b4",
   "metadata": {},
   "source": [
    "**词频（term frequency）**TF(t,d) 表示单词t在文档d中出现的次数\n",
    "\n",
    "**文档频度（document frequency）**DF(t,D) 表示包含单词t的文档的个数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aeff4d3",
   "metadata": {},
   "source": [
    "如果只使用词频（term frequency），会过于强调出现次数多的单词，这些单词可能并没有包含有用的信息（例如：a、the、of）。\n",
    "\n",
    "如何一个单词在语料库中到处存在，则说明这个单词在特定的文档中并没有特殊的含义。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd7b966",
   "metadata": {},
   "source": [
    "**逆文档频率（inverse document frequency）**是一个单词提供信息的量化表示：\n",
    "\n",
    "$IDF(t, D) = \\log \\frac{|D| + 1}{DF(t, D) + 1}$\n",
    "\n",
    "|D|表示语料库中文档的总数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e467f1",
   "metadata": {},
   "source": [
    "**TF-IDF** 就是**TF**和**IDF**的乘积：\n",
    "\n",
    "$TFIDF(t, d, D) = TF(t, d) \\cdot IDF(t, D)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "babef05f",
   "metadata": {},
   "source": [
    "#### 例子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a73d291c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09917ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62afb5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession\\\n",
    "        .builder\\\n",
    "        .appName(\"IfIdfExample\")\\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ed71cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentenceData = spark.createDataFrame([\n",
    "    (0.0, \"Hi I heard about Spark\"),\n",
    "    (0.0, \"I wish Java could use case classes\"),\n",
    "    (1.0, \"Logistic regression models are neat\")\n",
    "], [\"label\", \"sentence\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f82bec5",
   "metadata": {},
   "source": [
    "使用 Tokenizer 做分词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa5dbaf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(inputCol=\"sentence\", outputCol=\"words\")\n",
    "wordsData = tokenizer.transform(sentenceData)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af2d6987",
   "metadata": {},
   "source": [
    "计算 TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a797a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "hashingTF = HashingTF(inputCol=\"words\", outputCol=\"rawFeatures\", numFeatures=20)\n",
    "featurizedData = hashingTF.transform(wordsData)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "412c03bc",
   "metadata": {},
   "source": [
    "计算 TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d6c32d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")\n",
    "idfModel = idf.fit(featurizedData)\n",
    "rescaledData = idfModel.transform(featurizedData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ee7c7f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|            features|\n",
      "+-----+--------------------+\n",
      "|  0.0|(20,[6,8,13,16],[...|\n",
      "|  0.0|(20,[0,2,7,13,15,...|\n",
      "|  1.0|(20,[3,4,6,11,19]...|\n",
      "+-----+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rescaledData.select(\"label\", \"features\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "688cecaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336eb799",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
